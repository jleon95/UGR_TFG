\chapter{Feature selection}\label{ch:featureselection}
%************************************************

Like we mentioned before, the chosen approach for the feature selection step is a genetic algorithm. With a few modifications specific to our problem, the basic structure will be that of \acs{NSGA-II}.

We previously hinted in chapter \ref{ch:background} at a binary representation when dealing with this kind of task. It not only facilitates the overall implementation, but---as we already said---it also brings with it some easy yet effective operators.

\section{Feature selection procedure}

	The main body of the algorithm corresponds to a typical \acs{NSGA-II} layout. Let us see its general form before going over the different parts:

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Proc{NSGA-II}{

			\KwIn{population size, generations, data, max features}
			\KwOut{final population}
			population $\longleftarrow$ Initialize(population size, max features)\;
			evaluation $\longleftarrow$ Evaluate(population, data)\;
			population $\longleftarrow$ NDSort(population, evaluation)\;

			\For{$gen = 0$ \KwTo $max$ $generations$}{

				parents $\longleftarrow$ Selection(population)\;
				offspring $\longleftarrow$ CreateOffspring(parents)\;
				shared population $\longleftarrow$ population $\cup$ offspring\;
				evaluation $\longleftarrow$ Evaluate(shared population, data)\;
				shared population $\longleftarrow$ NDSort(shared population, evaluation)\;
				population $\longleftarrow$ Replace(shared population, population size)\;
			}

			\KwRet population\;
		}

		\caption{NSGA-II}

	\end{algorithm}

	\vspace{0.3cm}

	Notice that it returns the whole population from the last generation. Ideally, we want to take its first Pareto front and choose whatever solution we deem more appropriate for our needs.

	We can proceed to go now into more detail about the different functions that make up the body of the algorithm.

\newpage

	At the beginning, there is a randomized initialization of the population, so as to have something to start with:

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{Initialize}{

			\KwIn{population size, max features}
			\KwOut{population}
			population $\longleftarrow$ $\emptyset$\;
			\For{$i = 0$ \KwTo $population$ $size$}{
				population $\longleftarrow$ population $\cup$ RandomVector(max features)\;
			}

			\KwRet population\;
		}

		\caption{Population initialization}

	\end{algorithm}

	\vspace{0.3cm}

	In the actual code, each element of the population is created as a sequence of zeros which is then modified to introduce ones in random positions. These two numbers correspond to the intuitive notion of boolean false and true, respectively, telling us whether a given feature is chosen or not.

	After that, and also after each time we create a new population, we have to evaluate the fitness of its individuals. This is accomplished in \texttt{Evaluate}:

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{Evaluate}{

			\KwIn{population, data}
			\KwOut{evaluation}
			evaluation $\longleftarrow$ EmptyMatrix(population size, objective count)\;

			\For{$obj = 0$ \KwTo $objective$ $count$}{

				\For{$ind = 0$ \KwTo $population$ $size$}{

					evaluation[ind][obj] $\longleftarrow$ $F_{obj}$(population[ind], data)\;
				}
			}

			\KwRet evaluation\;
		}

		\caption{Population evaluation}

	\end{algorithm}

	\vspace{0.3cm}

	Here we assume that we already have the different $F_i$ at our disposal. Also, not all fitness functions necessarily use the data for their computations---we will discuss this soon---but it is written this way for uniformity.

\newpage

	The next operation is one of the keys of \acs{NSGA-II}: the non-dominated sorting. Let us first see the reasoning behind it before explaining how it is carried out.

	Diversity of solutions in the Pareto fronts is one main issue that \acs{NSGA-II} tries to address. It is clear that pertaining to a better Pareto front makes an individual rank higher; however, when comparing two individuals from the same front, we may want to choose that which is most distant to its neighbors. This is because similar solutions tend to score similarly in all aspects, but we need them to be as different as possible in order to explore the space better.

	This way, individuals with significant quality will naturally be in the top positions, but at the same time we make sure that differences are favored too. For clarity, we will break down the process into two steps, explained with the help of the original paper (\cite{deb2002fast}). Also, we will use some auxiliar functions to abstract behavior not relevant to our understanding of the concept.

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{NDSort}{

			\KwIn{population, evaluation}
			\KwOut{population}
			
			fronts $\longleftarrow$ ComputeFronts(evaluation)\;
			fronts $\longleftarrow$ ComputeDistances(fronts, evaluation)\;
			population $\longleftarrow$ $\emptyset$\;

			\For{$F_i$ \textbf{in} \textit{fronts}}{

				population $\longleftarrow$ population $\cup$ $F_i$\;
			}

			\KwRet population\;
		}

		\caption{Non-dominated sort steps}

	\end{algorithm}

	\vspace{0.3cm}

	The front computation step assigns a front to each individual of the population based on its fitness scores. Before delving into the details, let us define a few things:

	\begin{itemize}

		\item
		$p \prec q$: ``$p$ is not worse than $q$ in any objective and is better in at least one'', for two individuals $p$ and $q$. It is read as ``$p$ dominates $q$''.

		\item
		$S_p$: the set of individuals dominated by $p$.

		\item
		$n_p$: the count of individuals that dominate $p$.

		\item
		$F_i$: the different fronts. A lower $i$ means a better overall quality of the elements.

	\end{itemize}

	Remember that \texttt{evaluation} contains a row for every individual and that its elements are the different fitness scores; this means that we can think of an individual in terms of its associated row in this structure.

\newpage

	The pseudocode is as follows:

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{ComputeFronts}{

			\KwIn{evaluation}
			\KwOut{fronts}

			fronts $\longleftarrow$ $\{F_1, F_2,...,F_n\}$ \tcc*[r]{All of them empty}

			\For{$p$ $\in$ $evaluation$}{

				$S_p$ $\longleftarrow$ $\emptyset$\;
				$n_p = 0$\;

				\For{$q$ $\in$ $evaluation$}{

					\If{$p$ $\prec$ $q$}{
						$S_p$ $\longleftarrow$ $S_p$ $\cup$ $\{q\}$\;
					}
					\ElseIf{$q$ $\prec$ $p$}{
						$n_p$ $=$ $n_p$ + 1\;
					}
				}
				
				\If{$n_p$ \textbf{is} $0$}{
					$p$.front $=$ 1\;
					$F_1$ $\longleftarrow$ $F_1$ $\cup$ $\{p\}$\;
				}
			}

			i $=$ 1\;
			\While{$F_i$ $\neq$ $\emptyset$}{

				Q $\longleftarrow$ $\emptyset$ \tcc*[r]{Members of the next front}
				\For{$p$ $\in$ $F_i$}{

					\For{$q$ $\in$ $S_p$}{

						$n_q = n_q$ - 1\;
						\If{$n_q$ \textbf{is} $0$}{
							$q$.front $=$ i + 1\;
							Q $\longleftarrow$ Q $\cup$ $\{q\}$\;
						}
					}
				}
				i $=$ i + 1\;
				$F_i$ $\longleftarrow$ Q\;
			}

			\KwRet fronts\;
		}

		\caption{Front computation}

	\end{algorithm}

	\vspace{0.3cm}

	The second step (algorithm \ref{alg:crowding_distance}) will tell us how far each individual is from its neighbors---within its own front---on average.

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{ComputeDistances}{

			\KwIn{fronts, evaluation}
			\KwOut{fronts}

			\For{$F_i$ \textbf{in} \textit{fronts}}{

				n $=$ size($F_i$)\;
				\For{$j = 0$ \KwTo $n$}{
					$F_{ij}$.distance $= 0$\; 
				}

				evaluation\textsubscript{ i} $\longleftarrow$ GetEvaluations(evaluation, $F_i$)\;

				\For{$obj$ \textbf{in} \textit{columns(evaluation\textsubscript{ i})}}{

					objective $\longleftarrow$ Sort(evaluation\textsubscript{ i}[...][obj])\;
					$F_i$ $\longleftarrow$ SortBy($F_i$, objective)\;
					$F_{i1}$.distance $=$ $F_{in}$.distance $= \infty$\;
					range = objective[n] - objective[1]\;
					\For{$k = 2$ \KwTo $n-1$}{
						$F_{ik}$.distance $=$ $F_{ik}$.distance + (objective[k+1]-objective[k-1]) / range\;
					}
				}
				$F_i$ $\longleftarrow$ SortByDistance($F_i$) \tcc*[r]{Descending order}
			}

			\KwRet fronts\;
		}

		\caption{Crowding distance computation}\label{alg:crowding_distance}

	\end{algorithm}

	\vspace{0.3cm}

	We are now able to upgrade our $\prec$ operator to take into consideration the crowding distances. Let $p \prec_{nds} q$ be true if $p$.rank $<$ $q$.rank or $p$.rank $=$ $q$.rank and $p$.distance $>$ $q$.distance. We can use it now in our parent selection process:

	\vspace{0.29cm}

	\begin{algorithm}[H]

		\Fn{Selection}{

			\KwIn{population}
			\KwOut{parents}
			parents $\longleftarrow$ $\emptyset$\;

			\For{$i = 0$ \KwTo $size(population)$/2}{

				$p$, $q$ = RandomChoose(population, 2)\;
				\If{$p \prec_{nds} q$}{
					parents $\longleftarrow$ parents $\cup$ $\{p\}$\;
				}
				\ElseIf{$q \prec_{nds} p$}{
					parents $\longleftarrow$ parents $\cup$ $\{q\}$\;
				}
			}
		
			\KwRet parents\;
		}

		\caption{Selection operator}

	\end{algorithm}

	\vspace{0.3cm}

	There are several ways of deciding which individuals from the last generation we are going to use to create offspring. One of the most common is the \textit{Binary Tournament Selection} described here. The size of the parent pool is fixed to half the population in this instance, but it can be whatever we think is suitable.

	Our next function is in charge of making the offspring:

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{CreateOffspring}{

			\KwIn{parents}
			\KwOut{offspring}
			offspring $\longleftarrow$ $\emptyset$\;

			\For{$i = 0$ \KwTo \textit{size(parents)}}{
				$p_1$, $p_2$ = RandomChoose(parents, 2)\;
				\If{\textit{Random()} $\leq$ \textit{crossover probability}}{
					child $\longleftarrow$ Crossover($p_1$,$p_2$)\;
					\If{\textit{Random()} $\leq$ \textit{mutation probability}}{
						child $\longleftarrow$ Mutation(child)\;
					}
					offspring $\longleftarrow$ offspring $\cup$ $\{$child$\}$\;
				}
			}
			\KwRet offspring
		}

		\caption{Offspring creation}

	\end{algorithm}

	\vspace{0.3cm}

	Some parameters are up to the designer, such as how many offspring are returned, the crossover and mutation probabilities, or the operators. For the latter, some common alternatives are found in algorithms \ref{alg:singlepointx}, \ref{alg:twopointx}, \ref{alg:uniformx} and \ref{alg:flipbitsm}.

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{SinglePoint}{

			\KwIn{$p_1$, $p_2$}
			\KwOut{child}
			child $\longleftarrow$ $p_1$\;
			pivot $=$ RandomChoose(size($p_1$))\;
			\For{$i = pivot$ \KwTo \textit{size($p_1$)}}{
				child[i] $=$ $p_2$[i]\;
			}
			\KwRet child\;
		}

		\caption{Single-point crossover}\label{alg:singlepointx}

	\end{algorithm}

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{TwoPoint}{

			\KwIn{$p_1$, $p_2$}
			\KwOut{child}
			child $\longleftarrow$ $p_1$\;
			pivot\_1, pivot\_2 $=$ RandomChoose(size($p_1$), 2)\;
			\For{$i =$ \textit{pivot\_1} \KwTo \textit{pivot\_2}}{
				child[i] $=$ $p_2$[i]\;
			}
			\KwRet child\;
		}

		\caption{Two-point crossover}\label{alg:twopointx}

	\end{algorithm}

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{Uniform}{

			\KwIn{$p_1$, $p_2$}
			\KwOut{child}
			child $\longleftarrow$ EmptyVector(size($p_1$))\;
			\For{$i = 0$ \KwTo \textit{size($p_1$)}}{
				\If{$p_1[i]$ \textbf{equals} $p_2[i]$ \textbf{or} \textit{Random()} $\leq 0.5$}{
					child[i] = $p_1$[i]\;
				}
				\Else{
					child[i] = $p_2$[i]\;
				}
			}
			\KwRet child\;
		}

		\caption{Uniform crossover}\label{alg:uniformx}

	\end{algorithm}

	\vspace{0.3cm}

	\begin{algorithm}[H]

		\Fn{FlipBits}{

			\KwIn{individual, swaps}
			\KwOut{individual}

			positions $\longleftarrow$ RandomChoose(size(individuals), swaps)\;
			\For{$p$ $\in$ \textit{positions}}{
				individual[p] $=$ individual[p] + $1$ $\pmod{2}$\;
			}
			\KwRet child\;
		}

		\caption{Flip bits mutation}\label{alg:flipbitsm}

	\end{algorithm}

	\vspace{0.3cm}

	For visual examples of the above operators, refer to section \ref{sec:genetic_algorithms} of chapter \ref{ch:background}.